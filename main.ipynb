{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "338fe1c4-05a8-461f-8017-c502ba1acfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.5.0+cu124\n",
      "CUDA available: True\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5daa7f25-fe26-4948-8ab1-5b311dc0970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"data/\"):\n",
    "\t# path to zip file\n",
    "\tzip_path = \"cafa-6-protein-function-prediction.zip\"\n",
    "\n",
    "\t# folder to extract to\n",
    "\textract_dir = \"data\"\n",
    "\n",
    "\t# make sure the folder exists\n",
    "\tos.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "\t# extract\n",
    "\twith zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "\t\tzip_ref.extractall(extract_dir)\n",
    "\n",
    "\tprint(f\"Extracted all files to: {extract_dir}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7df76a22-bc93-42d4-a234-ab527d1bdec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sequences: 82404\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>seq_len</th>\n",
       "      <th>taxonomy</th>\n",
       "      <th>term</th>\n",
       "      <th>aspect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A0C5B5G6</td>\n",
       "      <td>MRWQEMGYIFYPRKLR</td>\n",
       "      <td>16</td>\n",
       "      <td>9606</td>\n",
       "      <td>GO:0001649</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A0C5B5G6</td>\n",
       "      <td>MRWQEMGYIFYPRKLR</td>\n",
       "      <td>16</td>\n",
       "      <td>9606</td>\n",
       "      <td>GO:0033687</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A0C5B5G6</td>\n",
       "      <td>MRWQEMGYIFYPRKLR</td>\n",
       "      <td>16</td>\n",
       "      <td>9606</td>\n",
       "      <td>GO:0005615</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A0C5B5G6</td>\n",
       "      <td>MRWQEMGYIFYPRKLR</td>\n",
       "      <td>16</td>\n",
       "      <td>9606</td>\n",
       "      <td>GO:0005634</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A0C5B5G6</td>\n",
       "      <td>MRWQEMGYIFYPRKLR</td>\n",
       "      <td>16</td>\n",
       "      <td>9606</td>\n",
       "      <td>GO:0005739</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     entry_id          sequence  seq_len  taxonomy        term aspect\n",
       "0  A0A0C5B5G6  MRWQEMGYIFYPRKLR       16      9606  GO:0001649      P\n",
       "1  A0A0C5B5G6  MRWQEMGYIFYPRKLR       16      9606  GO:0033687      P\n",
       "2  A0A0C5B5G6  MRWQEMGYIFYPRKLR       16      9606  GO:0005615      C\n",
       "3  A0A0C5B5G6  MRWQEMGYIFYPRKLR       16      9606  GO:0005634      C\n",
       "4  A0A0C5B5G6  MRWQEMGYIFYPRKLR       16      9606  GO:0005739      C"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "# Load sequences\n",
    "train_sequences = list(SeqIO.parse(\"data/Train/train_sequences.fasta\", \"fasta\"))\n",
    "print(f\"Total sequences: {len(train_sequences)}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "seq_df = pd.DataFrame({\n",
    "    \"entry_id\": [record.id for record in train_sequences],\n",
    "    \"sequence\": [str(record.seq) for record in train_sequences],\n",
    "})\n",
    "seq_df[\"seq_len\"] = seq_df[\"sequence\"].str.len()\n",
    "seq_df[\"entry_id\"] = seq_df[\"entry_id\"].str.extract(r\"sp\\|([^|]+)\\|\")[0]\n",
    "#seq_df.head()\n",
    "\n",
    "# Load taxonomy and GO terms\n",
    "tax_df = pd.read_csv(\"data/Train/train_taxonomy.tsv\", sep=\"\\t\",header=None)\n",
    "tax_df.columns = [\"entry_id\", \"taxonomy\"]\n",
    "terms_df = pd.read_csv(\"data/Train/train_terms.tsv\", sep=\"\\t\")\n",
    "terms_df.columns = terms_df.columns.str.lower()\n",
    "terms_df.rename(columns={\"entryid\": \"entry_id\"}, inplace=True)\n",
    "\n",
    "# Merge all\n",
    "train_df =  (\n",
    "    seq_df\n",
    "    .merge(tax_df, on=\"entry_id\", how=\"left\")\n",
    "    .merge(terms_df, on=\"entry_id\", how=\"left\")\n",
    ")\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66337f4a-1aa9-41ca-a088-8ea595569b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "\n",
    "records = list(SeqIO.parse(\"data/Test/testsuperset.fasta\", \"fasta\"))\n",
    "\n",
    "entry_ids = []\n",
    "tax_ids = []\n",
    "sequences = []\n",
    "\n",
    "for r in records:\n",
    "    parts = r.description.split()\n",
    "    entry_ids.append(parts[0])        # e.g., A0A0C5B5G6\n",
    "    tax_ids.append(parts[1])          # e.g., 9606\n",
    "    sequences.append(str(r.seq))\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    \"entry_id\": entry_ids,\n",
    "    \"tax_id\": tax_ids,\n",
    "    \"sequence\": sequences\n",
    "})\n",
    "\n",
    "test_df[\"seq_len\"] = test_df[\"sequence\"].str.len()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3eb89b39-37e4-4a32-b88f-8a766ea90d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sequences: 224309\n",
      "Train protein-function pairs: 537027\n",
      "Unique proteins in train: 82404\n",
      "Unique GO terms: 26125\n",
      "Proteins in both train and test: 82404\n"
     ]
    }
   ],
   "source": [
    "# Check data sizes and overlaps\n",
    "print(f\"Test sequences: {test_df.shape[0]}\")\n",
    "print(f\"Train protein-function pairs: {train_df.shape[0]}\")\n",
    "print(f\"Unique proteins in train: {train_df['entry_id'].nunique()}\")\n",
    "print(f\"Unique GO terms: {train_df['term'].nunique()}\")\n",
    "\n",
    "# Check for sequence overlap between train and test\n",
    "train_proteins = set(train_df['entry_id'].unique())\n",
    "test_proteins = set(test_df['entry_id'].unique())\n",
    "overlap = train_proteins.intersection(test_proteins)\n",
    "print(f\"Proteins in both train and test: {len(overlap)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1dd0798-3e0c-43e9-926a-b70f3196c89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO term frequency distribution:\n",
      "count    26125.000000\n",
      "mean        20.556057\n",
      "std        268.143836\n",
      "min          1.000000\n",
      "25%          2.000000\n",
      "50%          4.000000\n",
      "75%         12.000000\n",
      "max      33713.000000\n",
      "Name: count, dtype: float64\n",
      "Terms with ≥1 occurrences: 26125\n"
     ]
    }
   ],
   "source": [
    "# Analyze GO term frequency\n",
    "term_counts = train_df['term'].value_counts()\n",
    "print(\"GO term frequency distribution:\")\n",
    "print(term_counts.describe())\n",
    "\n",
    "# Focus on frequent terms \n",
    "min_occurrence = 1\n",
    "frequent_terms = term_counts[term_counts >= min_occurrence].index\n",
    "print(f\"Terms with ≥{min_occurrence} occurrences: {len(frequent_terms)}\")\n",
    "\n",
    "# Filter training data to frequent terms\n",
    "filtered_train_df = train_df[train_df['term'].isin(frequent_terms)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fd83909-29d4-4fed-8b5f-ae6a0b824dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ESM model...\n",
      "ESM model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import esm\n",
    "from Bio import SeqIO\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import scipy.sparse as sp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Loading ESM model...\")\n",
    "esm_model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "esm_model = esm_model.to(device)\n",
    "esm_model.eval()\n",
    "print(\"ESM model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4033afe8-8b52-4f13-bdb6-aaf7ca17dcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA SUMMARY ===\n",
      "Train df shape: (537027, 6)\n",
      "Test df shape: (224309, 4)\n",
      "\n",
      "=== TRAIN DATA PREVIEW ===\n",
      "     entry_id          sequence  seq_len  taxonomy        term aspect\n",
      "0  A0A0C5B5G6  MRWQEMGYIFYPRKLR       16      9606  GO:0001649      P\n",
      "1  A0A0C5B5G6  MRWQEMGYIFYPRKLR       16      9606  GO:0033687      P\n",
      "2  A0A0C5B5G6  MRWQEMGYIFYPRKLR       16      9606  GO:0005615      C\n",
      "3  A0A0C5B5G6  MRWQEMGYIFYPRKLR       16      9606  GO:0005634      C\n",
      "4  A0A0C5B5G6  MRWQEMGYIFYPRKLR       16      9606  GO:0005739      C\n",
      "\n",
      "=== TEST DATA PREVIEW ===\n",
      "     entry_id tax_id                                           sequence  \\\n",
      "0  A0A0C5B5G6   9606                                   MRWQEMGYIFYPRKLR   \n",
      "1  A0A1B0GTW7   9606  MLLLLLLLLLLPPLVLRVAASRCLHDETQKSVSLLRPPFSQLPSKS...   \n",
      "2      A0JNW5   9606  MAGIIKKQILKHLSRFTKNLSPDKINLSTLKGEGELKNLELDEEVL...   \n",
      "3      A0JP26   9606  MVAEVCSMPAASAVKKPFDLRSKMGKWCHHRFPCCRGSGKSNMGTS...   \n",
      "4      A0PK11   9606  MPGWFKKAWYGLASLLSFSSFILIIVALVVPHWLSGKILCQTGVDL...   \n",
      "\n",
      "   seq_len  \n",
      "0       16  \n",
      "1      788  \n",
      "2     1464  \n",
      "3      581  \n",
      "4      232  \n",
      "\n",
      "=== COLUMN NAMES ===\n",
      "Train columns: ['entry_id', 'sequence', 'seq_len', 'taxonomy', 'term', 'aspect']\n",
      "Test columns: ['entry_id', 'tax_id', 'sequence', 'seq_len']\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DATA SUMMARY ===\")\n",
    "print(f\"Train df shape: {train_df.shape}\")\n",
    "print(f\"Test df shape: {test_df.shape}\")\n",
    "\n",
    "print(\"\\n=== TRAIN DATA PREVIEW ===\")\n",
    "print(train_df.head())\n",
    "print(\"\\n=== TEST DATA PREVIEW ===\")\n",
    "print(test_df.head())\n",
    "\n",
    "print(\"\\n=== COLUMN NAMES ===\")\n",
    "print(f\"Train columns: {train_df.columns.tolist()}\")\n",
    "print(f\"Test columns: {test_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7505c57-28c1-4784-b94f-15c971fcddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, df, max_length=1024):\n",
    "        \"\"\"\n",
    "        df: DataFrame with 'entry_id' and 'sequence' columns\n",
    "        max_length: Truncate sequences longer than this\n",
    "        \"\"\"\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __hash__(self):\n",
    "        df_str = self.df.to_string(index=False, header=True)\n",
    "        return hash(df_str)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        entry_id = row['entry_id']\n",
    "        sequence = row['sequence'][:self.max_length]  # Truncate if too long\n",
    "        return entry_id, sequence\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_esm_embeddings(dataset, batch_size=8, show_progress=True, cache_file=\"esm_embeddings.pkl\"):\n",
    "    \"\"\"\n",
    "    Extract ESM embeddings for all sequences in dataset.\n",
    "    If embeddings are cached, load them from the cache file.\n",
    "    \n",
    "    Returns: dict {entry_id: embedding_vector}\n",
    "    \"\"\"\n",
    "    # Check if the embeddings are already cached\n",
    "    print(\"cache file: \", cache_file)\n",
    "    if os.path.exists(cache_file):\n",
    "        print(f\"Loading cached embeddings from {cache_file}\")\n",
    "        with open(cache_file, 'rb') as f:\n",
    "            embeddings = pickle.load(f)\n",
    "        return embeddings\n",
    "    \n",
    "    print(\"Extracting embeddings...\")\n",
    "\n",
    "    # Initialize dataloader\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    embeddings = {}\n",
    "\n",
    "    if show_progress:\n",
    "        from tqdm import tqdm\n",
    "        iterator = tqdm(dataloader, desc=\"Extracting embeddings\")\n",
    "    else:\n",
    "        iterator = dataloader\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            entry_ids, sequences = batch\n",
    "            \n",
    "            # Prepare batch for ESM\n",
    "            batch_data = [(entry_id, sequence) for entry_id, sequence in zip(entry_ids, sequences)]\n",
    "            batch_labels, batch_strs, batch_tokens = batch_converter(batch_data)\n",
    "            batch_tokens = batch_tokens.to(device)\n",
    "            \n",
    "            # Get embeddings \n",
    "            results = esm_model(batch_tokens, repr_layers=[esm_model.num_layers], return_contacts=False)\n",
    "            token_representations = results[\"representations\"][esm_model.num_layers]\n",
    "            \n",
    "            # Create protein embedding (mean of all tokens except CLS and PAD)\n",
    "            for i, entry_id in enumerate(entry_ids):\n",
    "                seq_len = len(batch_strs[i])\n",
    "                embedding = token_representations[i, 1:seq_len+1].mean(dim=0)  # Exclude CLS token\n",
    "                embeddings[entry_id] = embedding.cpu().numpy()\n",
    "\n",
    "            # Clear GPU memory\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # Cache the embeddings for future use\n",
    "    with open(cache_file, 'wb') as f:\n",
    "        pickle.dump(embeddings, f)\n",
    "        print(f\"Embeddings cached to {cache_file}\")\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def create_label_matrix(train_df, protein_list, term_list):\n",
    "    \"\"\"\n",
    "    Create binary label matrix for multi-label classification\n",
    "    Returns: sparse matrix (proteins x terms), protein_to_idx mapping\n",
    "    \"\"\"\n",
    "    protein_to_idx = {pid: idx for idx, pid in enumerate(protein_list)}\n",
    "    term_to_idx = {term: idx for idx, term in enumerate(term_list)}\n",
    "    \n",
    "    rows, cols = [], []\n",
    "    for _, row in train_df.iterrows():\n",
    "        if row['entry_id'] in protein_to_idx and row['term'] in term_to_idx:\n",
    "            rows.append(protein_to_idx[row['entry_id']])\n",
    "            cols.append(term_to_idx[row['term']])\n",
    "    \n",
    "    data = np.ones(len(rows))\n",
    "    label_matrix = sp.csr_matrix((data, (rows, cols)), \n",
    "                                shape=(len(protein_list), len(term_list)))\n",
    "    \n",
    "    return label_matrix, protein_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25ad4a2-6c00-464c-b4a8-a1fbe8c811da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples: 82404\n",
      "Unique proteins: 82404\n",
      "GO terms: 26125\n",
      "Creating ProteinDataset and extracting embeddings...\n",
      "cache file:  generated/esm_650m/esm_embeddings_train.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_train.pkl\n",
      "Feature matrix: X=(82404, 1280), Label matrix: y=(82404, 1542)\n",
      "Removing 122 GO terms with no positives in training: ['GO:0051897', 'GO:0006325', 'GO:0051649', 'GO:0000165', 'GO:0007204', 'GO:0070588', 'GO:0042826', 'GO:0051402', 'GO:0061844', 'GO:0007519']...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/100]: 100%|██████████████████████████████| 516/516 [00:05<00:00, 90.88batch/s, loss=0.0363]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.03632479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/100]: 100%|█████████████████████████████| 516/516 [00:05<00:00, 93.37batch/s, loss=0.00348]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Loss: 0.00348301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/100]: 100%|█████████████████████████████| 516/516 [00:05<00:00, 94.22batch/s, loss=0.00333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Loss: 0.00333062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/100]: 100%|█████████████████████████████| 516/516 [00:05<00:00, 93.30batch/s, loss=0.00329]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Loss: 0.00328700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/100]: 100%|█████████████████████████████| 516/516 [00:05<00:00, 91.91batch/s, loss=0.00328]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Loss: 0.00327745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/100]: 100%|█████████████████████████████| 516/516 [00:05<00:00, 94.70batch/s, loss=0.00327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Loss: 0.00326977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/100]: 100%|█████████████████████████████| 516/516 [00:05<00:00, 94.91batch/s, loss=0.00327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100], Loss: 0.00326941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/100]: 100%|█████████████████████████████| 516/516 [00:05<00:00, 92.26batch/s, loss=0.00327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100], Loss: 0.00326982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/100]: 100%|█████████████████████████████| 516/516 [00:05<00:00, 93.49batch/s, loss=0.00326]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100], Loss: 0.00326168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/100]: 100%|████████████████████████████| 516/516 [00:05<00:00, 88.85batch/s, loss=0.00325]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.00325325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/100]: 100%|████████████████████████████| 516/516 [00:05<00:00, 96.48batch/s, loss=0.00325]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Loss: 0.00324806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/100]: 100%|████████████████████████████| 516/516 [00:05<00:00, 94.89batch/s, loss=0.00324]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100], Loss: 0.00323963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/100]: 100%|████████████████████████████| 516/516 [00:05<00:00, 93.29batch/s, loss=0.00323]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100], Loss: 0.00322956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14/100]: 100%|████████████████████████████| 516/516 [00:05<00:00, 90.48batch/s, loss=0.00322]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100], Loss: 0.00321860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/100]: 100%|████████████████████████████| 516/516 [00:05<00:00, 92.04batch/s, loss=0.00321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100], Loss: 0.00320609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [16/100]: 100%|█████████████████████████████| 516/516 [00:05<00:00, 94.37batch/s, loss=0.0032]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100], Loss: 0.00319516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17/100]: 100%|████████████████████████████| 516/516 [00:05<00:00, 93.52batch/s, loss=0.00318]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100], Loss: 0.00318158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [18/100]: 100%|████████████████████████████| 516/516 [00:05<00:00, 93.58batch/s, loss=0.00316]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100], Loss: 0.00316289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19/100]: 100%|████████████████████████████| 516/516 [00:05<00:00, 94.76batch/s, loss=0.00315]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100], Loss: 0.00315301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20/100]: 100%|████████████████████████████| 516/516 [00:05<00:00, 94.49batch/s, loss=0.00313]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100], Loss: 0.00313218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [21/100]: 100%|████████████████████████████| 516/516 [00:05<00:00, 86.83batch/s, loss=0.00312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100], Loss: 0.00312107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [22/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 85.16batch/s, loss=0.00311]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100], Loss: 0.00310551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [23/100]: 100%|████████████████████████████| 516/516 [00:05<00:00, 87.98batch/s, loss=0.00309]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100], Loss: 0.00309168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [24/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 84.95batch/s, loss=0.00307]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100], Loss: 0.00307046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [25/100]: 100%|████████████████████████████| 516/516 [00:05<00:00, 86.73batch/s, loss=0.00305]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100], Loss: 0.00305088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [26/100]: 100%|████████████████████████████| 516/516 [00:05<00:00, 89.18batch/s, loss=0.00303]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100], Loss: 0.00303221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [27/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 84.34batch/s, loss=0.00302]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100], Loss: 0.00301817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [28/100]: 100%|██████████████████████████████| 516/516 [00:05<00:00, 88.84batch/s, loss=0.003]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/100], Loss: 0.00299918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [29/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 75.05batch/s, loss=0.00298]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/100], Loss: 0.00297872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [30/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 75.59batch/s, loss=0.00297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100], Loss: 0.00296866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [31/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 82.34batch/s, loss=0.00295]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/100], Loss: 0.00295135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [32/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 76.77batch/s, loss=0.00294]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/100], Loss: 0.00293739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [33/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 75.01batch/s, loss=0.00293]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/100], Loss: 0.00292724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [34/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 82.66batch/s, loss=0.00291]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/100], Loss: 0.00291285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [35/100]: 100%|█████████████████████████████| 516/516 [00:05<00:00, 90.50batch/s, loss=0.0029]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/100], Loss: 0.00290254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [36/100]: 100%|█████████████████████████████| 516/516 [00:06<00:00, 81.54batch/s, loss=0.0029]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/100], Loss: 0.00289925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [37/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 79.92batch/s, loss=0.00288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/100], Loss: 0.00288321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [38/100]: 100%|████████████████████████████| 516/516 [00:05<00:00, 90.79batch/s, loss=0.00287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/100], Loss: 0.00287334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [39/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 83.53batch/s, loss=0.00287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/100], Loss: 0.00286686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [40/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 78.86batch/s, loss=0.00285]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/100], Loss: 0.00285262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [41/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 77.67batch/s, loss=0.00285]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/100], Loss: 0.00284603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [42/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 84.97batch/s, loss=0.00284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/100], Loss: 0.00283819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [43/100]: 100%|████████████████████████████| 516/516 [00:05<00:00, 86.25batch/s, loss=0.00283]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/100], Loss: 0.00283119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [44/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 79.35batch/s, loss=0.00282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/100], Loss: 0.00282219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [45/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 80.11batch/s, loss=0.00282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/100], Loss: 0.00281581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [46/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 83.87batch/s, loss=0.00281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/100], Loss: 0.00280975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [47/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 80.99batch/s, loss=0.00281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/100], Loss: 0.00281039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [48/100]: 100%|█████████████████████████████| 516/516 [00:06<00:00, 84.75batch/s, loss=0.0028]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/100], Loss: 0.00279881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [49/100]: 100%|████████████████████████████| 516/516 [00:05<00:00, 88.69batch/s, loss=0.00279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/100], Loss: 0.00279200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [50/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 74.09batch/s, loss=0.00278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/100], Loss: 0.00278221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [51/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 78.21batch/s, loss=0.00278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/100], Loss: 0.00278058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [52/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 77.42batch/s, loss=0.00278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/100], Loss: 0.00277632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [53/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 78.38batch/s, loss=0.00277]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/100], Loss: 0.00276931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [54/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 78.89batch/s, loss=0.00277]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/100], Loss: 0.00276586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [55/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 80.78batch/s, loss=0.00276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/100], Loss: 0.00276000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [56/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 79.06batch/s, loss=0.00275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/100], Loss: 0.00275456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [57/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 78.75batch/s, loss=0.00275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/100], Loss: 0.00274913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [58/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 78.09batch/s, loss=0.00275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/100], Loss: 0.00275041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [59/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 78.82batch/s, loss=0.00275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/100], Loss: 0.00274709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [60/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 77.88batch/s, loss=0.00275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/100], Loss: 0.00274672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [61/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 81.11batch/s, loss=0.00274]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/100], Loss: 0.00273884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [62/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 77.51batch/s, loss=0.00273]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/100], Loss: 0.00273146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [63/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 76.69batch/s, loss=0.00273]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/100], Loss: 0.00273051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [64/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 75.63batch/s, loss=0.00272]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/100], Loss: 0.00272427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [65/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 77.07batch/s, loss=0.00272]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/100], Loss: 0.00272203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [66/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 74.69batch/s, loss=0.00272]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/100], Loss: 0.00271936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [67/100]: 100%|████████████████████████████| 516/516 [00:07<00:00, 72.48batch/s, loss=0.00272]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/100], Loss: 0.00271793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [68/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 74.41batch/s, loss=0.00272]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/100], Loss: 0.00271687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [69/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 74.83batch/s, loss=0.00272]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/100], Loss: 0.00272001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [70/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 75.97batch/s, loss=0.00272]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/100], Loss: 0.00271543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [71/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 79.20batch/s, loss=0.00271]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/100], Loss: 0.00270762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [72/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 78.69batch/s, loss=0.00271]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/100], Loss: 0.00270613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [73/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 75.56batch/s, loss=0.00271]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/100], Loss: 0.00270557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [74/100]: 100%|█████████████████████████████| 516/516 [00:06<00:00, 75.62batch/s, loss=0.0027]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/100], Loss: 0.00270233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [75/100]: 100%|█████████████████████████████| 516/516 [00:06<00:00, 76.59batch/s, loss=0.0027]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/100], Loss: 0.00269875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [76/100]: 100%|█████████████████████████████| 516/516 [00:06<00:00, 79.53batch/s, loss=0.0027]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76/100], Loss: 0.00269706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [77/100]: 100%|█████████████████████████████| 516/516 [00:06<00:00, 78.54batch/s, loss=0.0027]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/100], Loss: 0.00269552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [78/100]: 100%|████████████████████████████| 516/516 [00:05<00:00, 86.03batch/s, loss=0.00269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/100], Loss: 0.00269368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [79/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 83.18batch/s, loss=0.00269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/100], Loss: 0.00269264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [80/100]: 100%|████████████████████████████| 516/516 [00:07<00:00, 73.23batch/s, loss=0.00269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/100], Loss: 0.00268743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [81/100]: 100%|████████████████████████████| 516/516 [00:07<00:00, 73.24batch/s, loss=0.00269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/100], Loss: 0.00268523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [82/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 79.91batch/s, loss=0.00269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/100], Loss: 0.00268683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [83/100]: 100%|████████████████████████████| 516/516 [00:07<00:00, 70.17batch/s, loss=0.00269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/100], Loss: 0.00268571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [84/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 74.56batch/s, loss=0.00268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/100], Loss: 0.00268020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [85/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 79.31batch/s, loss=0.00268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/100], Loss: 0.00268136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [86/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 76.60batch/s, loss=0.00268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/100], Loss: 0.00267745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [87/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 77.71batch/s, loss=0.00267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/100], Loss: 0.00267422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [88/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 84.40batch/s, loss=0.00268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/100], Loss: 0.00267874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [89/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 79.89batch/s, loss=0.00267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/100], Loss: 0.00267197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [90/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 78.81batch/s, loss=0.00268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/100], Loss: 0.00267512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [91/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 85.02batch/s, loss=0.00267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/100], Loss: 0.00266712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [92/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 85.68batch/s, loss=0.00267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/100], Loss: 0.00266685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [93/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 85.31batch/s, loss=0.00267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/100], Loss: 0.00266861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [94/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 79.81batch/s, loss=0.00266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/100], Loss: 0.00266470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [95/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 77.66batch/s, loss=0.00267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/100], Loss: 0.00266581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [96/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 74.66batch/s, loss=0.00267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/100], Loss: 0.00266769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [97/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 83.09batch/s, loss=0.00266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/100], Loss: 0.00266013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [98/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 78.95batch/s, loss=0.00266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/100], Loss: 0.00266091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [99/100]: 100%|████████████████████████████| 516/516 [00:06<00:00, 79.75batch/s, loss=0.00266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99/100], Loss: 0.00266052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [100/100]: 100%|███████████████████████████| 516/516 [00:05<00:00, 86.09batch/s, loss=0.00266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 0.00265777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "# class MultiOutputNN(nn.Module):\n",
    "# \tdef __init__(self, input_size, output_size, hidden_size=1000):\n",
    "# \t\tsuper(MultiOutputNN, self).__init__()\n",
    "# \t\tself.fc_in = nn.Linear(input_size, hidden_size)\n",
    "# \t\tself.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "# \t\tself.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "# \t\tself.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "# \t\tself.fc_out = nn.Linear(hidden_size, output_size)\n",
    "# \t\tself.relu = nn.ReLU()\n",
    "# \t\tself.sigmoid = nn.Sigmoid()\n",
    "\t\n",
    "# \tdef forward(self, x):\n",
    "# \t\tx = self.relu(self.fc_in(x))\n",
    "# \t\tx = self.relu(self.fc1(x))\n",
    "# \t\tx = self.relu(self.fc2(x))\n",
    "# \t\tx = self.relu(self.fc3(x))\n",
    "# \t\tx = self.fc_out(x)\n",
    "# \t\treturn self.sigmoid(x)\n",
    "\n",
    "class MultiOutputCNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_channels=32, kernel_size=10):\n",
    "        super(MultiOutputCNN, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(1, hidden_channels, kernel_size, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(hidden_channels, hidden_channels, kernel_size, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Global pooling → fixed-size output\n",
    "        self.global_pool = nn.AdaptiveMaxPool1d(1)\n",
    "\n",
    "        self.fc_out = nn.Linear(hidden_channels, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, embedding_dim)\n",
    "        x = x.unsqueeze(1)              # → (batch, 1, embedding_dim)\n",
    "        x = self.conv(x)                # → (batch, hidden_channels, L)\n",
    "        x = self.global_pool(x)         # → (batch, hidden_channels, 1)\n",
    "        x = x.squeeze(-1)               # → (batch, hidden_channels)\n",
    "        x = self.fc_out(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "\n",
    "\n",
    "def training(train_df, test_df, term_counts, min_occurrence, batch_size=16):\n",
    "\t# Select GO terms with enough occurrences\n",
    "\tterms = term_counts[term_counts >= min_occurrence].index\n",
    "\ttrain = train_df[train_df['term'].isin(terms)]\n",
    "\t\t\n",
    "\t# Select proteins present in test_df\n",
    "\t# common_proteins = set(train['entry_id']).intersection(set(test_df['entry_id']))\n",
    "\tproteins = list(set(train['entry_id']))\n",
    "\t\t\n",
    "\ttrain = train[train['entry_id'].isin(proteins)]\n",
    "\ttrain = train.drop_duplicates(subset=['entry_id'])\n",
    "\ttest = test_df[test_df['entry_id'].isin(proteins)]\n",
    "\t\n",
    "\tprint(f\"Training examples: {len(train)}\")\n",
    "\tprint(f\"Unique proteins: {len(proteins)}\")\n",
    "\tprint(f\"GO terms: {len(terms)}\")\n",
    "\t# Create dataset and extract embeddings\n",
    "\tprint(\"Creating ProteinDataset and extracting embeddings...\")\n",
    "\tdataset = ProteinDataset(test)\n",
    "\tembeddings = get_esm_embeddings(dataset, batch_size=1, cache_file=f\"generated/esm_650m/esm_embeddings_train.pkl\")\n",
    "\t\n",
    "\t# Build sparse label matrix\n",
    "\tterms_2 = term_counts[(term_counts > 50)].index\n",
    "\tterms = terms_2\n",
    "\ty_train, _protein_map = create_label_matrix(train, proteins, terms)\n",
    "\tX_train = np.array([embeddings[pid] for pid in proteins])\n",
    "\t\n",
    "\tprint(f\"Feature matrix: X={X_train.shape}, Label matrix: y={y_train.shape}\")\n",
    "\t\n",
    "\tdef train_safe_classifier(X, y, terms, test_size=0.2, lr=0.001, epochs=100):\n",
    "\t\tX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\t\t\n",
    "\t\t# Identify columns (GO terms) with at least 1 positive sample\n",
    "\t\tvalid_cols = np.where(y_train.sum(axis=0) > 0)[0]\n",
    "\t\tif len(valid_cols) < y_train.shape[1]:\n",
    "\t\t\tremoved_terms = [terms[i] for i in range(len(terms)) if i not in valid_cols]\n",
    "\t\t\tprint(f\"Removing {len(removed_terms)} GO terms with no positives in training: {removed_terms[:10]}{'...' if len(removed_terms) > 10 else ''}\")\n",
    "\t\t\n",
    "\t\t# Filter y to valid columns (GO terms)\n",
    "\t\ty_train_filtered = y_train[:, valid_cols]\n",
    "\t\ty_val_filtered = y_val[:, valid_cols]\n",
    "\t\tfiltered_terms = [terms[i] for i in valid_cols]\n",
    "\t\t\n",
    "\t\t# Train multi-output neural network model\n",
    "\t\t# base_clf = MLPClassifier(random_state=42, max_iter=100, solver='adam', hidden_layer_sizes=(100,100), activation='relu', verbose=True)\n",
    "\t\t# clf = MultiOutputClassifier(base_clf)\n",
    "\t\t# clf.fit(X_train, y_train_filtered)\n",
    "\t\t\n",
    "\t\t# y_pred = clf.predict(X_val)\n",
    "\t\t# f1 = f1_score(y_val_filtered, y_pred, average='micro')\n",
    "\t\t# precision = precision_score(y_val_filtered, y_pred, average='micro')\n",
    "\t\t# recall = recall_score(y_val_filtered, y_pred, average='micro')\n",
    "\t\t\n",
    "\t\t# print(\"=== VALIDATION RESULTS ===\")\n",
    "\t\t# print(f\"Micro F1-score: {f1:.4f}\")\n",
    "\t\t# print(f\"Micro Precision: {precision:.4f}\")\n",
    "\t\t# print(f\"Micro Recall: {recall:.4f}\")\n",
    "\t\t# print(f\"Predicted labels: {y_pred.sum()} / {y_val_filtered.sum()} actual\")\n",
    "\t\t\n",
    "\t\t# return clf, (f1, precision, recall), filtered_terms\n",
    "\n",
    "\t\tX_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "\t\ty_train_tensor = torch.tensor(y_train_filtered, dtype=torch.float32).to(device)\n",
    "\t\tX_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "\t\ty_val_tensor = torch.tensor(y_val_filtered, dtype=torch.float32).to(device)\n",
    "\t\t\n",
    "\t\ttrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\t\ttrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\t\t\n",
    "\t\t# Initialize the model\n",
    "\t\tinput_size = X_train.shape[1]\n",
    "\t\toutput_size = y_train_filtered.shape[1]\n",
    "\t\tmodel = MultiOutputCNN(input_size, output_size)\n",
    "\t\tmodel = model.to(device)\n",
    "\t\t\n",
    "\t\t# Define loss function and optimizer\n",
    "\t\tcriterion = nn.BCELoss()  # Use BCE loss for multi-label classification\n",
    "\t\toptimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\t\t# Training loop\n",
    "\t\tfor epoch in range(epochs):\n",
    "\t\t\tmodel.train()\n",
    "\t\t\tepoch_loss = 0.0\n",
    "\t\t\twith tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{epochs}]\", unit=\"batch\", ncols=100) as t:\n",
    "\t\t\t\tfor batch_idx, (X_batch, y_batch) in enumerate(t):\n",
    "\t\t\t\t\toptimizer.zero_grad()\n",
    "\n",
    "\t\t\t\t\t# Forward pass\n",
    "\t\t\t\t\ty_pred_train = model(X_batch)\n",
    "\n",
    "\t\t\t\t\t# Compute loss\n",
    "\t\t\t\t\tloss = criterion(y_pred_train, y_batch)\n",
    "\t\t\t\t\tepoch_loss += loss.item()\n",
    "\n",
    "\t\t\t\t\t# Backward pass and optimization\n",
    "\t\t\t\t\tloss.backward()\n",
    "\t\t\t\t\toptimizer.step()\n",
    "\n",
    "\t\t\t\t\t# Update the tqdm progress bar with current loss\n",
    "\t\t\t\t\tt.set_postfix(loss=epoch_loss / (batch_idx + 1))\n",
    "\t\t\t\n",
    "\t\t\tavg_loss = epoch_loss / len(train_loader)\n",
    "\t\t\tprint(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.8f}\")\n",
    "\n",
    "\t\t# model.eval()\n",
    "\t\t# with torch.no_grad():\n",
    "\t\t# \ty_pred_val = model(X_val_tensor)\n",
    "\t\t# \t# print(y_pred_val)\n",
    "\t\t# \ty_pred_val = (y_pred_val > 0.01).float()  # Convert logits to binary predictions (0 or 1)\n",
    "\n",
    "\t\t# \tf1 = f1_score(y_val_tensor.cpu(), y_pred_val.cpu(), average='micro')\n",
    "\t\t# \tprecision = precision_score(y_val_tensor.cpu(), y_pred_val.cpu(), average='micro')\n",
    "\t\t# \trecall = recall_score(y_val_tensor.cpu(), y_pred_val.cpu(), average='micro')\n",
    "\n",
    "\t\t# \tprint(\"=== VALIDATION RESULTS ===\")\n",
    "\t\t# \tprint(f\"Micro F1-score: {f1:.4f}\")\n",
    "\t\t# \tprint(f\"Micro Precision: {precision:.4f}\")\n",
    "\t\t# \tprint(f\"Micro Recall: {recall:.4f}\")\n",
    "\t\t# \tprint(f\"Predicted labels: {y_pred_val.sum()} / {y_val_tensor.sum()} actual\")\n",
    "\t\t\n",
    "\t\treturn model, (0, 0, 0), filtered_terms\n",
    "\t\t\n",
    "\t# Train and evaluate\n",
    "\tclassifier, metrics, filtered_terms = train_safe_classifier(X_train, y_train.toarray(), terms)\n",
    "\t\t\n",
    "\treturn classifier, metrics, filtered_terms, X_train, y_train\n",
    "\n",
    "classifier, metrics, filtered_terms, X_train_after, y_train_after = training(\n",
    "\tfiltered_train_df, test_df, term_counts,\n",
    "\tmin_occurrence=1,\n",
    "\tbatch_size=128\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7437a51-9e88-4b38-846a-124190c4382c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_0.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_0.pkl\n",
      "Processing batch 2/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_1.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_1.pkl\n",
      "Processing batch 3/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_2.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_2.pkl\n",
      "Processing batch 4/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_3.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_3.pkl\n",
      "Processing batch 5/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_4.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_4.pkl\n",
      "Processing batch 6/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_5.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_5.pkl\n",
      "Processing batch 7/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_6.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_6.pkl\n",
      "Processing batch 8/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_7.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_7.pkl\n",
      "Processing batch 9/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_8.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_8.pkl\n",
      "Processing batch 10/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_9.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_9.pkl\n",
      "Processing batch 11/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_10.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_10.pkl\n",
      "Processing batch 12/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_11.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_11.pkl\n",
      "Processing batch 13/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_12.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_12.pkl\n",
      "Processing batch 14/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_13.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_13.pkl\n",
      "Processing batch 15/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_14.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_14.pkl\n",
      "Processing batch 16/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_15.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_15.pkl\n",
      "Processing batch 17/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_16.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_16.pkl\n",
      "Processing batch 18/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_17.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_17.pkl\n",
      "Processing batch 19/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_18.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_18.pkl\n",
      "Processing batch 20/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_19.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_19.pkl\n",
      "Processing batch 21/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_20.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_20.pkl\n",
      "Processing batch 22/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_21.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_21.pkl\n",
      "Processing batch 23/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_22.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_22.pkl\n",
      "Processing batch 24/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_23.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_23.pkl\n",
      "Processing batch 25/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_24.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_24.pkl\n",
      "Processing batch 26/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_25.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_25.pkl\n",
      "Processing batch 27/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_26.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_26.pkl\n",
      "Processing batch 28/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_27.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_27.pkl\n",
      "Processing batch 29/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_28.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_28.pkl\n",
      "Processing batch 30/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_29.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_29.pkl\n",
      "Processing batch 31/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_30.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_30.pkl\n",
      "Processing batch 32/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_31.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_31.pkl\n",
      "Processing batch 33/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_32.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_32.pkl\n",
      "Processing batch 34/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_33.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_33.pkl\n",
      "Processing batch 35/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_34.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_34.pkl\n",
      "Processing batch 36/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_35.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_35.pkl\n",
      "Processing batch 37/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_36.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_36.pkl\n",
      "Processing batch 38/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_37.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_37.pkl\n",
      "Processing batch 39/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_38.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_38.pkl\n",
      "Processing batch 40/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_39.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_39.pkl\n",
      "Processing batch 41/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_40.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_40.pkl\n",
      "Processing batch 42/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_41.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_41.pkl\n",
      "Processing batch 43/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_42.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_42.pkl\n",
      "Processing batch 44/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_43.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_43.pkl\n",
      "Processing batch 45/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_44.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_44.pkl\n",
      "Processing batch 46/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_45.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_45.pkl\n",
      "Processing batch 47/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_46.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_46.pkl\n",
      "Processing batch 48/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_47.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_47.pkl\n",
      "Processing batch 49/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_48.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_48.pkl\n",
      "Processing batch 50/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_49.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_49.pkl\n",
      "Processing batch 51/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_50.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_50.pkl\n",
      "Processing batch 52/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_51.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_51.pkl\n",
      "Processing batch 53/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_52.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_52.pkl\n",
      "Processing batch 54/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_53.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_53.pkl\n",
      "Processing batch 55/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_54.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_54.pkl\n",
      "Processing batch 56/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_55.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_55.pkl\n",
      "Processing batch 57/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_56.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_56.pkl\n",
      "Processing batch 58/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_57.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_57.pkl\n",
      "Processing batch 59/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_58.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_58.pkl\n",
      "Processing batch 60/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_59.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_59.pkl\n",
      "Processing batch 61/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_60.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_60.pkl\n",
      "Processing batch 62/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_61.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_61.pkl\n",
      "Processing batch 63/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_62.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_62.pkl\n",
      "Processing batch 64/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_63.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_63.pkl\n",
      "Processing batch 65/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_64.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_64.pkl\n",
      "Processing batch 66/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_65.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_65.pkl\n",
      "Processing batch 67/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_66.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_66.pkl\n",
      "Processing batch 68/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_67.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_67.pkl\n",
      "Processing batch 69/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_68.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_68.pkl\n",
      "Processing batch 70/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_69.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_69.pkl\n",
      "Processing batch 71/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_70.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_70.pkl\n",
      "Processing batch 72/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_71.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_71.pkl\n",
      "Processing batch 73/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_72.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_72.pkl\n",
      "Processing batch 74/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_73.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_73.pkl\n",
      "Processing batch 75/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_74.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_74.pkl\n",
      "Processing batch 76/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_75.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_75.pkl\n",
      "Processing batch 77/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_76.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_76.pkl\n",
      "Processing batch 78/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_77.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_77.pkl\n",
      "Processing batch 79/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_78.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_78.pkl\n",
      "Processing batch 80/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_79.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_79.pkl\n",
      "Processing batch 81/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_80.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_80.pkl\n",
      "Processing batch 82/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_81.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_81.pkl\n",
      "Processing batch 83/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_82.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_82.pkl\n",
      "Processing batch 84/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_83.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_83.pkl\n",
      "Processing batch 85/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_84.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_84.pkl\n",
      "Processing batch 86/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_85.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_85.pkl\n",
      "Processing batch 87/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_86.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_86.pkl\n",
      "Processing batch 88/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_87.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_87.pkl\n",
      "Processing batch 89/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_88.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_88.pkl\n",
      "Processing batch 90/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_89.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_89.pkl\n",
      "Processing batch 91/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_90.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_90.pkl\n",
      "Processing batch 92/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_91.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_91.pkl\n",
      "Processing batch 93/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_92.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_92.pkl\n",
      "Processing batch 94/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_93.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_93.pkl\n",
      "Processing batch 95/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_94.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_94.pkl\n",
      "Processing batch 96/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_95.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_95.pkl\n",
      "Processing batch 97/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_96.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_96.pkl\n",
      "Processing batch 98/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_97.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_97.pkl\n",
      "Processing batch 99/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_98.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_98.pkl\n",
      "Processing batch 100/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_99.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_99.pkl\n",
      "Processing batch 101/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_100.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_100.pkl\n",
      "Processing batch 102/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_101.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_101.pkl\n",
      "Processing batch 103/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_102.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_102.pkl\n",
      "Processing batch 104/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_103.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_103.pkl\n",
      "Processing batch 105/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_104.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_104.pkl\n",
      "Processing batch 106/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_105.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_105.pkl\n",
      "Processing batch 107/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_106.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_106.pkl\n",
      "Processing batch 108/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_107.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_107.pkl\n",
      "Processing batch 109/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_108.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_108.pkl\n",
      "Processing batch 110/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_109.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_109.pkl\n",
      "Processing batch 111/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_110.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_110.pkl\n",
      "Processing batch 112/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_111.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_111.pkl\n",
      "Processing batch 113/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_112.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_112.pkl\n",
      "Processing batch 114/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_113.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_113.pkl\n",
      "Processing batch 115/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_114.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_114.pkl\n",
      "Processing batch 116/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_115.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_115.pkl\n",
      "Processing batch 117/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_116.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_116.pkl\n",
      "Processing batch 118/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_117.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_117.pkl\n",
      "Processing batch 119/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_118.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_118.pkl\n",
      "Processing batch 120/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_119.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_119.pkl\n",
      "Processing batch 121/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_120.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_120.pkl\n",
      "Processing batch 122/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_121.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_121.pkl\n",
      "Processing batch 123/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_122.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_122.pkl\n",
      "Processing batch 124/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_123.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_123.pkl\n",
      "Processing batch 125/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_124.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_124.pkl\n",
      "Processing batch 126/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_125.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_125.pkl\n",
      "Processing batch 127/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_126.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_126.pkl\n",
      "Processing batch 128/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_127.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_127.pkl\n",
      "Processing batch 129/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_128.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_128.pkl\n",
      "Processing batch 130/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_129.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_129.pkl\n",
      "Processing batch 131/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_130.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_130.pkl\n",
      "Processing batch 132/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_131.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_131.pkl\n",
      "Processing batch 133/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_132.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_132.pkl\n",
      "Processing batch 134/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_133.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_133.pkl\n",
      "Processing batch 135/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_134.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_134.pkl\n",
      "Processing batch 136/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_135.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_135.pkl\n",
      "Processing batch 137/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_136.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_136.pkl\n",
      "Processing batch 138/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_137.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_137.pkl\n",
      "Processing batch 139/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_138.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_138.pkl\n",
      "Processing batch 140/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_139.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_139.pkl\n",
      "Processing batch 141/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_140.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_140.pkl\n",
      "Processing batch 142/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_141.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_141.pkl\n",
      "Processing batch 143/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_142.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_142.pkl\n",
      "Processing batch 144/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_143.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_143.pkl\n",
      "Processing batch 145/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_144.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_144.pkl\n",
      "Processing batch 146/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_145.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_145.pkl\n",
      "Processing batch 147/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_146.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_146.pkl\n",
      "Processing batch 148/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_147.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_147.pkl\n",
      "Processing batch 149/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_148.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_148.pkl\n",
      "Processing batch 150/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_149.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_149.pkl\n",
      "Processing batch 151/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_150.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_150.pkl\n",
      "Processing batch 152/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_151.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_151.pkl\n",
      "Processing batch 153/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_152.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_152.pkl\n",
      "Processing batch 154/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_153.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_153.pkl\n",
      "Processing batch 155/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_154.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_154.pkl\n",
      "Processing batch 156/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_155.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_155.pkl\n",
      "Processing batch 157/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_156.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_156.pkl\n",
      "Processing batch 158/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_157.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_157.pkl\n",
      "Processing batch 159/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_158.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_158.pkl\n",
      "Processing batch 160/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_159.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_159.pkl\n",
      "Processing batch 161/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_160.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_160.pkl\n",
      "Processing batch 162/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_161.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_161.pkl\n",
      "Processing batch 163/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_162.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_162.pkl\n",
      "Processing batch 164/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_163.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_163.pkl\n",
      "Processing batch 165/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_164.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_164.pkl\n",
      "Processing batch 166/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_165.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_165.pkl\n",
      "Processing batch 167/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_166.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_166.pkl\n",
      "Processing batch 168/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_167.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_167.pkl\n",
      "Processing batch 169/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_168.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_168.pkl\n",
      "Processing batch 170/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_169.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_169.pkl\n",
      "Processing batch 171/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_170.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_170.pkl\n",
      "Processing batch 172/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_171.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_171.pkl\n",
      "Processing batch 173/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_172.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_172.pkl\n",
      "Processing batch 174/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_173.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_173.pkl\n",
      "Processing batch 175/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_174.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_174.pkl\n",
      "Processing batch 176/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_175.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_175.pkl\n",
      "Processing batch 177/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_176.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_176.pkl\n",
      "Processing batch 178/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_177.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_177.pkl\n",
      "Processing batch 179/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_178.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_178.pkl\n",
      "Processing batch 180/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_179.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_179.pkl\n",
      "Processing batch 181/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_180.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_180.pkl\n",
      "Processing batch 182/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_181.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_181.pkl\n",
      "Processing batch 183/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_182.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_182.pkl\n",
      "Processing batch 184/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_183.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_183.pkl\n",
      "Processing batch 185/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_184.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_184.pkl\n",
      "Processing batch 186/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_185.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_185.pkl\n",
      "Processing batch 187/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_186.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_186.pkl\n",
      "Processing batch 188/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_187.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_187.pkl\n",
      "Processing batch 189/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_188.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_188.pkl\n",
      "Processing batch 190/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_189.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_189.pkl\n",
      "Processing batch 191/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_190.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_190.pkl\n",
      "Processing batch 192/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_191.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_191.pkl\n",
      "Processing batch 193/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_192.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_192.pkl\n",
      "Processing batch 194/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_193.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_193.pkl\n",
      "Processing batch 195/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_194.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_194.pkl\n",
      "Processing batch 196/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_195.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_195.pkl\n",
      "Processing batch 197/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_196.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_196.pkl\n",
      "Processing batch 198/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_197.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_197.pkl\n",
      "Processing batch 199/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_198.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_198.pkl\n",
      "Processing batch 200/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_199.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_199.pkl\n",
      "Processing batch 201/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_200.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_200.pkl\n",
      "Processing batch 202/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_201.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_201.pkl\n",
      "Processing batch 203/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_202.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_202.pkl\n",
      "Processing batch 204/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_203.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_203.pkl\n",
      "Processing batch 205/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_204.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_204.pkl\n",
      "Processing batch 206/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_205.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_205.pkl\n",
      "Processing batch 207/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_206.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_206.pkl\n",
      "Processing batch 208/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_207.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_207.pkl\n",
      "Processing batch 209/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_208.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_208.pkl\n",
      "Processing batch 210/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_209.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_209.pkl\n",
      "Processing batch 211/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_210.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_210.pkl\n",
      "Processing batch 212/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_211.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_211.pkl\n",
      "Processing batch 213/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_212.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_212.pkl\n",
      "Processing batch 214/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_213.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_213.pkl\n",
      "Processing batch 215/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_214.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_214.pkl\n",
      "Processing batch 216/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_215.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_215.pkl\n",
      "Processing batch 217/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_216.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_216.pkl\n",
      "Processing batch 218/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_217.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_217.pkl\n",
      "Processing batch 219/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_218.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_218.pkl\n",
      "Processing batch 220/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_219.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_219.pkl\n",
      "Processing batch 221/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_220.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_220.pkl\n",
      "Processing batch 222/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_221.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_221.pkl\n",
      "Processing batch 223/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_222.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_222.pkl\n",
      "Processing batch 224/225 (1000 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_223.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_223.pkl\n",
      "Processing batch 225/225 (309 proteins)...\n",
      "cache file:  generated/esm_650m/esm_embeddings_test_224.pkl\n",
      "Loading cached embeddings from generated/esm_650m/esm_embeddings_test_224.pkl\n",
      "Predictions saved to protein_predictions1.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'protein_predictions1.csv'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def predict(classifier, test_df, term_list, batch_size=1000, esm_batch_size=8, output_file=\"predictions.csv\"):\n",
    "\t\"\"\"\n",
    "\tPredict GO terms for a large set of proteins.\n",
    "\tSaves predictions incrementally to CSV to avoid memory issues.\n",
    "\t\t\t\n",
    "\tParameters:\n",
    "\t\tclassifier : trained multi-output classifier\n",
    "\t\ttest_df   : DataFrame with 'entry_id' and 'sequence'\n",
    "\t\tterm_list  : list of terms used during training\n",
    "\t\tbatch_size : number of proteins per batch\n",
    "\t\tesm_batch_size : batch size for ESM embeddings\n",
    "\t\toutput_file: path to save predictions CSV\n",
    "\t\"\"\"\n",
    "\n",
    "\tclassifier.eval()\n",
    "\t# Initialize CSV with headers\n",
    "\tcolumns = ['entry_id', 'GO_term', 'probability']\n",
    "\tpd.DataFrame(columns=columns).to_csv(output_file, index=False)\n",
    "\ttest_df = test_df.sort_values(by='sequence', key=lambda x: x.str.len(), ascending=False)\n",
    "\t# Process in batches\n",
    "\tnum_batches = (len(test_df) - 1) // batch_size + 1\n",
    "\tfor i in range(num_batches):\n",
    "\t\tbatch_df = test_df.iloc[i*batch_size : (i+1)*batch_size]\n",
    "\t\tbatch_dataset = ProteinDataset(batch_df)\n",
    "\t\t\n",
    "\t\tprint(f\"Processing batch {i+1}/{num_batches} ({len(batch_df)} proteins)...\")\n",
    "\t\t\n",
    "\t\t# Extract embeddings\n",
    "\t\tcache_file = f\"generated/esm_650m/esm_embeddings_test_{i}.pkl\"\n",
    "\t\tbatch_embeddings = get_esm_embeddings(batch_dataset, batch_size=esm_batch_size, show_progress=True, cache_file=cache_file)\n",
    "\t\tbatch_proteins = list(batch_embeddings.keys())\n",
    "\t\tX_batch = np.array([batch_embeddings[pid] for pid in batch_proteins])\n",
    "\t\t\n",
    "\t\t# Predictions\n",
    "\t\tX_batch_tensor = torch.tensor(X_batch, dtype=torch.float32).to(device)\n",
    "\t\ty_pred_batch = classifier(X_batch_tensor)\n",
    "\t\ty_pred_batch = y_pred_batch.cpu()\n",
    "\t\t# Prepare rows to save\n",
    "\t\trows = []\n",
    "\t\tfor j, pid in enumerate(batch_proteins):\n",
    "\t\t\tprob_list = []\n",
    "\t\t\tfor k, term in enumerate(term_list):\n",
    "\t\t\t\tprob = y_pred_batch[j, k].item()\n",
    "\n",
    "\t\t\t\tif (prob > 1e-4):\n",
    "\t\t\t\t\t# rows.append({'entry_id': pid, 'GO_term': term, 'probability': prob})\n",
    "\t\t\t\t\tprob_list.append((term, prob))\n",
    "\t\t\tsorted_prob_list = sorted(prob_list, key=lambda x: -x[1])[:25]\n",
    "\t\t\tfor term, prob in sorted_prob_list:\n",
    "\t\t\t\t\trows.append({'entry_id': pid, 'GO_term': term, 'probability': prob})\n",
    "\n",
    "\t\t# Append to CSV\n",
    "\t\tpd.DataFrame(rows).to_csv(output_file, mode='a', header=False, index=False)\n",
    "\t\t\n",
    "\tprint(f\"Predictions saved to {output_file}\")\n",
    "\treturn output_file\n",
    "\n",
    "# Predict on all proteins (~225k)\n",
    "predict(\n",
    "    classifier=classifier,\n",
    "    test_df=test_df,\n",
    "    term_list=filtered_terms,\n",
    "    batch_size=1000,      # process 1k proteins per loop\n",
    "    esm_batch_size=4,     # ESM embeddings batch size for GPU\n",
    "    output_file=\"protein_predictions1.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c20f6d3-6953-460e-b224-7c31529fc7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def prepare_cafa_submission(pred_csv, go_obo_file, output_file=\"submission.tsv\", max_terms=1500):\n",
    "    \"\"\"\n",
    "    - Loads raw prediction CSV (entry_id, GO_term, probability)\n",
    "    - Propagates predictions up the GO hierarchy\n",
    "    - Limits to max_terms per protein\n",
    "    - Formats final CAFA submission file\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Preparing CAFA Submission File ===\")\n",
    "\n",
    "    print(\"Loading predictions...\")\n",
    "    df = pd.read_csv(pred_csv)\n",
    "\n",
    "    print(\"Loading GO ontology...\")\n",
    "    parents = {}\n",
    "\n",
    "    # Parse go-basic.obo to build term → parents dictionary\n",
    "    with open(go_obo_file, 'r') as f:\n",
    "        current_term = None\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"id: GO:\"):\n",
    "                current_term = line.split(\"id: \")[1]\n",
    "                parents[current_term] = []\n",
    "            if line.startswith(\"is_a: GO:\") and current_term:\n",
    "                parent_term = line.split(\"is_a: \")[1].split()[0]\n",
    "                parents[current_term].append(parent_term)\n",
    "\n",
    "    print(\"Propagating predictions to parent terms...\")\n",
    "    propagated_rows = []\n",
    "\n",
    "    for protein, group in df.groupby(\"entry_id\"):\n",
    "        term_scores = dict(zip(group.GO_term, group.probability))\n",
    "\n",
    "        # BFS upward propagation\n",
    "        queue = list(term_scores.keys())\n",
    "        visited = set()\n",
    "\n",
    "        while queue:\n",
    "            term = queue.pop()\n",
    "            if term in visited: \n",
    "                continue\n",
    "            visited.add(term)\n",
    "\n",
    "            if term in parents:\n",
    "                for p in parents[term]:\n",
    "                    new_score = term_scores.get(term, 0)\n",
    "                    term_scores[p] = max(term_scores.get(p, 0), new_score)\n",
    "                    queue.append(p)\n",
    "\n",
    "        # Keep highest prob terms and limit to max_terms\n",
    "        top_terms = sorted(term_scores.items(), key=lambda x: x[1], reverse=True)[:max_terms]\n",
    "\n",
    "        for term, score in top_terms:\n",
    "            if score > 0:  # CAFA requirement: no zeroes\n",
    "                propagated_rows.append([protein, term, round(score, 3)])\n",
    "\n",
    "    print(\"Saving formatted submission file...\")\n",
    "    sub = pd.DataFrame(propagated_rows, columns=[\"ProteinID\", \"GO_ID\", \"Score\"])\n",
    "    sub.to_csv(output_file, sep=\"\\t\", index=False, header=False)\n",
    "\n",
    "    print(f\"\\nSubmission ready: {output_file}\")\n",
    "    print(f\"Total predictions: {len(sub)}\")\n",
    "    return sub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "060b8274-048f-47cf-8f47-78a031f952a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Preparing CAFA Submission File ===\n",
      "Loading predictions...\n",
      "Loading GO ontology...\n",
      "Propagating predictions to parent terms...\n",
      "Saving formatted submission file...\n",
      "\n",
      "Submission ready: submission.tsv\n",
      "Total predictions: 18675818\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProteinID</th>\n",
       "      <th>GO_ID</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A017SE81</td>\n",
       "      <td>GO:0005515</td>\n",
       "      <td>0.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A017SE81</td>\n",
       "      <td>GO:0005488</td>\n",
       "      <td>0.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A017SE81</td>\n",
       "      <td>GO:0003674</td>\n",
       "      <td>0.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A017SE81</td>\n",
       "      <td>GO:0005886</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A017SE81</td>\n",
       "      <td>GO:0016020</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18675813</th>\n",
       "      <td>X6R8R1</td>\n",
       "      <td>GO:0019209</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18675814</th>\n",
       "      <td>X6R8R1</td>\n",
       "      <td>GO:0019887</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18675815</th>\n",
       "      <td>X6R8R1</td>\n",
       "      <td>GO:0019207</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18675816</th>\n",
       "      <td>X6R8R1</td>\n",
       "      <td>GO:0005096</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18675817</th>\n",
       "      <td>X6R8R1</td>\n",
       "      <td>GO:0060589</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18675818 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ProteinID       GO_ID  Score\n",
       "0         A0A017SE81  GO:0005515  0.089\n",
       "1         A0A017SE81  GO:0005488  0.089\n",
       "2         A0A017SE81  GO:0003674  0.089\n",
       "3         A0A017SE81  GO:0005886  0.055\n",
       "4         A0A017SE81  GO:0016020  0.055\n",
       "...              ...         ...    ...\n",
       "18675813      X6R8R1  GO:0019209  0.003\n",
       "18675814      X6R8R1  GO:0019887  0.003\n",
       "18675815      X6R8R1  GO:0019207  0.003\n",
       "18675816      X6R8R1  GO:0005096  0.003\n",
       "18675817      X6R8R1  GO:0060589  0.003\n",
       "\n",
       "[18675818 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_cafa_submission(\n",
    "    pred_csv=\"protein_predictions1.csv\",\n",
    "    go_obo_file=\"data/Train/go-basic.obo\",\n",
    "    output_file=\"submission.tsv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e7ba675-82c0-4fa8-bd56-a700f123fdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle competitions submit -c cafa-6-protein-function-prediction -f submission.tsv -m \"esm 150m + nn 100x100\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
